{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fFm7RfIBKHP"
      },
      "source": [
        "## Data preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zW0jlsVTBKHP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.regularizers import l1\n",
        "from PIL import Image\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import Input,Conv2D, MaxPooling2D, UpSampling2D,concatenate,BatchNormalization,Conv2DTranspose,Flatten\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from keras import layers\n",
        "import shutil\n",
        "from sklearn import preprocessing\n",
        "from sklearn.cluster import KMeans,Birch,MeanShift\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from random import choice\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "import math\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8UyubZTBKHP",
        "outputId": "dd32eafb-d226-4036-87b8-8ed54e6429a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "# List all files in the '/content/' directory\n",
        "a = os.listdir('/content/')\n",
        "# Loop through the files and attempt to remove directories that have integer names\n",
        "for i in a:\n",
        "    try:\n",
        "        # If the file name is an integer, delete the directory\n",
        "        int(i)\n",
        "        shutil.rmtree('/content/' + i)\n",
        "    except:\n",
        "        # Print the file name if it's not an integer or can't be deleted\n",
        "        print(i)\n",
        "\n",
        "# Install the Kaggle library to access datasets\n",
        "!pip install kaggle\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the .kaggle directory to store API key for Kaggle access\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Copy the kaggle.json file (API key) from your Google Drive to the .kaggle directory\n",
        "!cp /content/drive/MyDrive/brain/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions for the kaggle.json file to make it readable\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the brain dataset from Kaggle\n",
        "!kaggle datasets download -d othmanebazine/braindata\n",
        "\n",
        "# Extract the downloaded dataset zip file\n",
        "zip = zipfile.ZipFile('braindata.zip')\n",
        "zip.extractall()\n",
        "\n",
        "# Rename the extracted 'data' folder to 'dataset'\n",
        "os.rename('/content/data', '/content/dataset')\n",
        "\n",
        "# Load the brain data CSV file from Google Drive into a pandas DataFrame\n",
        "df_filled = pd.read_csv('/content/drive/MyDrive/brain/oasis_cross-sectional.csv')\n",
        "\n",
        "# Load test and train index data from text files\n",
        "index_test = np.loadtxt('test_index.txt', dtype=str).astype('object')\n",
        "index_train = np.loadtxt('train_index.txt', dtype=str).astype('object')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "stbVutcntJfn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Function to create training data by pairing images based on label and class\n",
        "def sub_create_data(image, label, classe, state):\n",
        "    # Initialize lists to store image pairs and corresponding labels\n",
        "    x_train = []\n",
        "    label_train = []\n",
        "    class_train = []\n",
        "\n",
        "    # Loop through each unique label in the dataset\n",
        "    for i in np.unique(label):\n",
        "        # Depending on the state, find indices where the class matches the condition\n",
        "        if state == 1:\n",
        "            index_1 = np.where((label == i) & (classe == 1))[0]\n",
        "            index_0 = np.where((label == i) & (classe == 0))[0]\n",
        "        elif state == 0:\n",
        "            index_1 = np.where((label == i) & (classe == 0))[0]\n",
        "            index_0 = np.where((label == i) & (classe == 1))[0]\n",
        "        elif state == 2:\n",
        "            index_1 = np.where((label == i) & (classe == 1))[0]\n",
        "            index_0 = np.where((label == i) & (classe == 2))[0]\n",
        "\n",
        "        # Create pairs of images based on index_1 and index_0\n",
        "        for j in index_1:\n",
        "            for l in index_0:\n",
        "                img2 = image[j]  # Image with index j\n",
        "                img3 = image[l]  # Image with index l\n",
        "\n",
        "                # Combine the two images into one array and add to the training set\n",
        "                s = np.array([img2, img3])\n",
        "                x_train.append(s)\n",
        "                label_train.append(i)\n",
        "\n",
        "    # Convert lists to NumPy arrays for better performance\n",
        "    x_train = np.array(x_train).astype('uint8')\n",
        "    label_train = np.array(label_train).astype('int16')\n",
        "\n",
        "    # Shuffle the data before returning\n",
        "    x_train, label_train = shuffle(x_train, label_train)\n",
        "\n",
        "    return x_train, label_train\n",
        "\n",
        "# Function to create the final dataset by generating triplets of images for training\n",
        "def create_data(image, label, classe, dimentia, state=0, nmbr=50):\n",
        "    # Call sub_create_data to get paired images and labels\n",
        "    x_train, label_train = sub_create_data(image, label, classe, state)\n",
        "\n",
        "    # Initialize lists to store the triplets and corresponding labels\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    Label = []\n",
        "\n",
        "    # Number of unique labels and a counter\n",
        "    k = len(np.unique(label_train))\n",
        "    l = 0\n",
        "    shape = (224, 192, 1)  # Shape of the images (height, width, channels)\n",
        "\n",
        "    # Loop through each unique label in the dataset\n",
        "    for i in np.unique(label_train):\n",
        "        # Get the indices where label_train equals the current label\n",
        "        index0 = np.where(label_train == i)[0]\n",
        "        lenght = len(index0)\n",
        "\n",
        "        # Generate triplets of images for training\n",
        "        for _ in range(nmbr):\n",
        "            t = np.unique(label_train)[l % k]  # Select a different label\n",
        "            if t != i:\n",
        "                # Find the indices for the selected different label\n",
        "                index1 = np.where(label_train == t)[0]\n",
        "\n",
        "                # Choose images from the current label and the different label\n",
        "                choice0 = index0[l % lenght]\n",
        "                choice1 = np.random.choice(index1)\n",
        "\n",
        "                # Create a triplet by concatenating the images along the channel axis\n",
        "                s = np.concatenate([\n",
        "                    x_train[choice0][0].reshape(shape),  # First image from the pair\n",
        "                    x_train[choice0][1].reshape(shape),  # Second image from the pair\n",
        "                    x_train[choice1][0].reshape(shape)   # Third image from different label\n",
        "                ], axis=2)\n",
        "\n",
        "                # Add the triplet and the corresponding label to the training set\n",
        "                X_train.append(s)\n",
        "                Y_train.append(x_train[choice1][1].reshape(shape))  # Second image of the different label\n",
        "                Label.append(label_train[choice1])  # Label of the different image\n",
        "\n",
        "            l += 1\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    X_train = np.array(X_train).astype('uint8')\n",
        "    Y_train = np.array(Y_train)\n",
        "    Label = np.array(Label)\n",
        "\n",
        "    # Shuffle the data before returning\n",
        "    X_train, Y_train, Label = shuffle(X_train, Y_train, Label)\n",
        "\n",
        "    return X_train, Y_train, Label\n",
        "\n",
        "# Call the create_data function to generate the training data\n",
        "x_train, y_train, Label = create_data(images_train, labels_train, classes_train, state=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8ejMsXJLE0m"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECmVC_AhLE0n"
      },
      "outputs": [],
      "source": [
        "# Define the input shape for the autoencoder model\n",
        "input_img = Input(shape=(224, 192, 3))  # Input shape with 3 channels (change if needed)\n",
        "\n",
        "# Split input image into two parts: X (first 2 channels) and Y (third channel)\n",
        "X = input_img[:, :, :, :2]  # Select the first 2 channels from the input\n",
        "Y = input_img[:, :, :, 2]   # Select the third channel from the input\n",
        "\n",
        "# Reshape the input to match the desired format for the model\n",
        "X = layers.Reshape((224, 192, 2))(X)\n",
        "Y = layers.Reshape((224, 192, 1))(Y)\n",
        "\n",
        "# ------------------ Encoder 1 (for X input) ------------------\n",
        "\n",
        "# First layer of convolutions followed by pooling\n",
        "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(X)\n",
        "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv1)\n",
        "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D((2, 2), padding='same')(conv1)\n",
        "\n",
        "# Second block of convolutions followed by pooling\n",
        "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv2)\n",
        "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D((2, 2), padding='same')(conv2)\n",
        "\n",
        "# Third block of convolutions followed by pooling\n",
        "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3)\n",
        "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D((2, 2), padding='same')(conv3)\n",
        "\n",
        "# Fourth block of convolutions followed by pooling\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "pool4 = MaxPooling2D((2, 2), padding='same')(conv4)\n",
        "\n",
        "# Final convolution layer for the encoder\n",
        "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool4)\n",
        "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "# Store the pooling layers for later concatenation in the decoder\n",
        "pools = [pool1, pool2, pool3, pool4]\n",
        "\n",
        "# ------------------ Encoder 2 (for Y input) ------------------\n",
        "\n",
        "# First layer of convolutions for Y followed by pooling\n",
        "Y_2 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(Y)\n",
        "Y_2 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = MaxPooling2D((2, 2), padding='same')(Y_2)\n",
        "\n",
        "# Second block of convolutions followed by pooling\n",
        "Y_2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = MaxPooling2D((2, 2), padding='same')(Y_2)\n",
        "\n",
        "# Third block of convolutions followed by pooling\n",
        "Y_2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = MaxPooling2D((2, 2), padding='same')(Y_2)\n",
        "\n",
        "# Fourth block of convolutions followed by pooling\n",
        "Y_2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(Y_2)\n",
        "Y_2 = MaxPooling2D((2, 2), padding='same')(Y_2)\n",
        "\n",
        "# ------------------ Merge Encoders ------------------\n",
        "\n",
        "# Concatenate the outputs from Encoder 1 and Encoder 2\n",
        "a = concatenate([conv5, Y_2], axis=-1)\n",
        "\n",
        "# ------------------ Decoder ------------------\n",
        "\n",
        "# First layer of the decoder\n",
        "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(a)\n",
        "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "# First upsampling and concatenation\n",
        "concat1 = concatenate([conv6, pools[3]], axis=-1)\n",
        "up1 = UpSampling2D((2, 2))(concat1)\n",
        "\n",
        "# Second layer of the decoder\n",
        "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
        "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "# Second upsampling and concatenation\n",
        "concat2 = concatenate([conv7, pools[2]], axis=-1)\n",
        "up2 = UpSampling2D((2, 2))(concat2)\n",
        "\n",
        "# Third layer of the decoder\n",
        "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv8)\n",
        "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "# Third upsampling and concatenation\n",
        "concat3 = concatenate([conv8, pools[1]], axis=-1)\n",
        "up3 = UpSampling2D((2, 2))(concat3)\n",
        "\n",
        "# Fourth layer of the decoder\n",
        "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(up3)\n",
        "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv9)\n",
        "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "# Fourth upsampling and concatenation\n",
        "concat4 = concatenate([conv9, pools[0]], axis=-1)\n",
        "up4 = UpSampling2D((2, 2))(concat4)\n",
        "\n",
        "# Final output layer to generate the decoded image\n",
        "decoded = Conv2D(4, (3, 3), activation='relu', padding='same')(up4)\n",
        "decoded = Conv2D(1, (3, 3), activation='relu', padding='same')(decoded)\n",
        "\n",
        "# ------------------ Autoencoder Model ------------------\n",
        "\n",
        "# Create the autoencoder model that maps input_img to decoded output\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the model using Adam optimizer and Mean Absolute Error (MAE) loss\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRknzVn2LE0p"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train,y_train,epochs=50,batch_size=128,shuffle=True,validation_split=0.15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKDIw_h1LE0q"
      },
      "outputs": [],
      "source": [
        "autoencoder.save(\"/content/drive/MyDrive/brain/denoise_decoder1.2.1.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3f0PcArxBKHQ",
        "yBccpVhT2p-o",
        "A9ZatJAeLE0r",
        "rtV5uK87JaxJ",
        "HsC_wMM0JaxK",
        "1svVJ7fOJaxN",
        "MXiEBsBf3bJV",
        "ttLXhBdI3bJX",
        "My8l-sl53bJd",
        "hVH4AYwB3bJg",
        "COOYnVXAbljf"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}